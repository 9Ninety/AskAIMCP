# Ask AI MCP Server

A **Model Context Protocol (MCP) server** that enables AI models to consult with another AI model through tool calling. This server acts as a bridge, allowing AI assistants to ask questions to different AI models when they need help, alternative perspectives, code reviews, or expert opinions on complex problems. It supports multiple AI providers and is designed for seamless integration with MCP-compatible clients.

## ‚ú® Features

- **Multiple AI Providers**: OpenAI, Anthropic, Google AI Studio, Perplexity, and OpenAI-compatible endpoints
- **Reasoning Model Support**: Configurable reasoning effort for advanced models across all providers
- **Efficient Context Handling**: Single-call design for maximum efficiency and cost-effectiveness
- **Flexible Configuration**: Optional parameters for temperature, token limits, and custom endpoints
- **Production Ready**: Comprehensive error handling, validation, and TypeScript support

## üì¶ Installation

### Prerequisites

- Node.js 24.0.0 or higher
- API key for your chosen AI provider

### Quick Start (Recommended)

The easiest way to use this MCP server is with npx:

```json
{
  "mcpServers": {
    "ask-ai": {
      "command": "npx",
      "args": ["ask-ai-mcp"],
      "env": {
        "PROVIDER": "openai",
        "MODEL": "o3-2025-04-16",
        "API_KEY": "your_api_key_here"
      }
    }
  }
}
```

### From Source (Advanced)

For development or customization:

```bash
git clone <link to repository>
cd ask-ai-mcp
pnpm install
pnpm run build
```

Then reference the built server in your MCP configuration:

```json
{
  "mcpServers": {
    "ask-ai": {
      "command": "node",
      "args": ["/path/to/ask-ai-mcp/dist/server.js"],
      "env": {
        "PROVIDER": "openai",
        "MODEL": "o3-2025-04-16",
        "API_KEY": "your_api_key_here"
      }
    }
  }
}
```

## ‚öôÔ∏è Configuration

### Required Environment Variables

| Variable   | Description                                                                                |
| :--------- | :----------------------------------------------------------------------------------------- |
| `PROVIDER` | The AI provider to use. `openai`, `anthropic`, `google`, `perplexity`, `openai-compatible` |
| `MODEL`    | The model name from the selected provider.                                                 |
| `API_KEY`  | Your API key for the chosen provider.                                                      |

### Optional Environment Variables

| Variable           | Description                                                                                 |
| :----------------- | :------------------------------------------------------------------------------------------ |
| `TEMPERATURE`      | Sampling temperature for the model (e.g., `0.7`).                                           |
| `MAX_TOKENS`       | Maximum number of tokens to generate (e.g., `10000`).                                       |
| `BASE_URL`         | Custom endpoint for `openai-compatible` providers.                                          |
| `REASONING_EFFORT` | For reasoning models: `low`, `medium`, `high`, `max`, or a budget string (e.g., `"10000"`). |

### Provider Examples

#### OpenAI

```ini
PROVIDER=openai
MODEL=o3-2025-04-16
API_KEY=your_openai_api_key
# Optional
REASONING_EFFORT=medium  # low, medium, high, max, or budget like "10000"
```

#### Anthropic

```ini
PROVIDER=anthropic
MODEL=claude-opus-4-20250514
API_KEY=your_anthropic_api_key
```

#### Google AI Studio

```ini
PROVIDER=google
MODEL=gemini-2.5-pro-preview-06-05
API_KEY=your_google_api_key
```

#### Perplexity

```ini
PROVIDER=perplexity
MODEL=sonar-pro
API_KEY=your_perplexity_api_key
```

#### OpenAI-Compatible

```ini
PROVIDER=openai-compatible
MODEL=your_model_name
API_KEY=your_api_key
BASE_URL=https://your-endpoint.com/v1
```

### üõ†Ô∏è Available Tool

Once integrated, AI models can use the `ask_ai` tool:

```json
{
  "name": "ask_ai",
  "arguments": {
    "question": "How can I optimize this React component?",
    "context": "I have a React component that renders 1000+ items and re-renders frequently causing performance issues. Current code: [include your code here]"
  }
}
```

## üìÑ License

This project is licensed under the [GNU General Public License, version 2](LICENSE).
